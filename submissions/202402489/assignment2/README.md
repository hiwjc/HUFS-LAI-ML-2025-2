# MNIST 분류 실험 결과

## 기본 모델 성능
- 최종 테스트 정확도: 96.80%
- 훈련 시간: 0분 47초

## 실험 결과
### 실험 1: [ learning rate와 epoch를 변인으로 한 실험]
- 변경사항: (1) learnong rate 실험 : learning rate가 [0.0001, 0.0003, 0.001]일때 에포크를 3씩 각각 돌리며 loss의 변화와 최종 정확도를 관찰한다.
            (2) epoch 실험 : epoch를 1에서 5까지 학습시킨 모델의 정확도를 관찰한다.
- 결과:


   <img width="710" height="412" alt="image" src="https://github.com/user-attachments/assets/65dcaf65-f375-4721-8df7-bb4d2f3782f7" />

- 분석:

  (1) learning rate가 해당 실험에서 주어진 범위 안에서는 늘어날수록 전체적인 acc가 높아지는 것을 볼 수 있다. lr의 변화에 따른 acc의 경향성을 더 정확하게 확인하기 위해서는 더 많은 lr값들을 실험해야 할 필요성이 느껴진다.
  또한 예상대로 epoch를 높일수록 acc가 증가하는 양상을 보였다. 여기서 주목해야 할 부분은 거의 epoch 5 근처에서 acc가 수렴하고 있음이 보여지는데, 이는 이 이상으로 더 모델의 정확도를 높이기 위해서는 단순한 epoch 증가로는 어렵다는 점을 시사한다. 이 상태에서 5 이상으로 에포크를 늘린다고 하더라도 과적합 등의 문제가 발생할 수 있으므로 이 이상의 acc 증가를 위해서는 다른 하이퍼 파라미터나 모델 구조를 고려해야 된다고 분석된다.

  (2) 또한 Dynamic Mode Decomposition (DMD)의 람다 값을 통해 학습 loss의 변화 정도를 분석해 보았다. lr = 0.0003일때가 비교적 다른 lr 보다 수렴 정도가 높은 것을 알 수 있다. (람다값 0.5489) 
  하지만 학습 단계에서 loss의 감소 속도가 빨랐던 lr에서 최선의 acc가 도출된 것은 아니기에 , “학습 단계의 loss 감소 속도가 빠르다 = 좋은 모델이다”는 개인적인 직관은 다소 잘못되었을 수 있다는 것을 알 수 있다.

### 실험 2: [활성화 함수를 변인으로 한 실험을 실행]
- 변경사항: (1) 활성화 함수를 ReLU 에서 Tanh로 바꾸어 실험1에서의 수치들을 관찰
- 결과:


  <img width="727" height="410" alt="image" src="https://github.com/user-attachments/assets/16fd2fd9-c181-4d4f-8204-4652d76de4b2" />

- 분석:

  (1) 활성화 함수가 ReLU 였을때와 같이 lr가 증가함에 따라서 정확도가 높아지는 부분은 실험 1과 동일하게 관찰된다. 주목할 부분은 Tanh를 활성화 함수로 사용하니 epoch 5 근처에서 수렴하던 acc가 계속해서 향상하고 있는것을 알 수 있다. 혹시 원인이 과적합은 아닌지 (Tanh의 잘 알려져 있는 위험성) 확인해 볼 필요가 있다.


  (2) 역시 DMD로 loss 수렴 정도를 분석하였다. 활성화 함수를 Tanh로 사용하였을때 수렴하는 정도가 더 크다고 볼 수 있으나 차이가 크지는 않다. 오히려 수렴 정도가 크다는 것이 과적합의 지표로 연결시킬 수 있을거라는 예상을 하게된다.

## 결론 및 인사이트
- 가장 효과적인 개선 방법: 수치만 관찰하였을 때는 (1) learning rate를 증가시키는 방법 (2) 에포크를 늘리는 방법 (3) 활성화 함수로 Tanh 사용 중 (3)번이 가장 높은 최종acc의 개선 여지가 보였으나 (수렴 안함) (3)의 개선 결과는 과적합이 의심되므로 과적합이 맞는지 검증해야 하며, (1)의 경우 lr의 값의 범위를 늘려 더 최적의 lr을 찾는 추후 실험을 해보아야 
  이 중 어떤 것이 가장 효과적인지 분명해 질것 같다.
- 관찰된 패턴: lr 증가와 에포크 증가 모두 acc를 개선시키는데 효과가 있으나 어느값의 lr과 acc가 최적인지 찾는 추가 실험 및 알고리즘의 필요성이 느껴진다. 또한 보조 지표로서 활용하려고 했던 DMD값은 최종 acc와는 관련이 떨어지는 것과 같은 관찰을 하였다.
- 추가 개선 아이디어: 과적합을 진단할 수 있는 역할을 DMD가 할 수 있는지를 검증하여 (Tanh로 바꾸어 학습시킬때 loss 감소가 더 컸었기 때문에, 과적합 발생시 loss 감소가 급격하지 않을까 하는 예상에 대한 검증) 개선의 정도가 과적합인지 아닌지 판단할 수 있도록 하거나, 모델 구조를 다른 모델 후보들을 사용해 본다. (CNN 등)
