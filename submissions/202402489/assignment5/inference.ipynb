{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ë¡œ íŒë‹¨ë˜ëŠ” ëª¨ë¸ì— ëŒ€í•œ ì •ë³´ë¥¼ .pt íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ë‹¤ìŒ ìµœì¢… ì§ë¬´ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤"
      ],
      "metadata": {
        "id": "nYRbWTZenlw1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uS0zhsqnaEF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn  # nn ëª¨ë“ˆ ì¶”ê°€\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel  # AutoModel ì¶”ê°€\n",
        "import os\n",
        "\n",
        "# ========================================================================================\n",
        "# [Model Architecture] ë…ë¦½ ì‹¤í–‰ì„ ìœ„í•´ ëª¨ë¸ í´ë˜ìŠ¤ ì§ì ‘ ì •ì˜\n",
        "# ========================================================================================\n",
        "class ReviewRatingRegressor(nn.Module):\n",
        "    def __init__(self, n_targets=6):\n",
        "        super(ReviewRatingRegressor, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained('klue/bert-base') # ëª¨ë¸ëª… í•˜ë“œì½”ë”© (í•™ìŠµê³¼ ë™ì¼)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_targets)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        _, pooler_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=False\n",
        "        )\n",
        "        output = self.drop(pooler_output)\n",
        "        return self.out(output), pooler_output\n",
        "\n",
        "# ========================================================================================\n",
        "# [Preprocessing] ì „ì²˜ë¦¬ í•¨ìˆ˜ ì§ì ‘ ì •ì˜\n",
        "# ========================================================================================\n",
        "def local_preprocess_dataframe(df):\n",
        "    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°\n",
        "    df.columns = [str(col).strip() for col in df.columns]\n",
        "\n",
        "    # ì»¬ëŸ¼ ë§¤í•‘ (í•œê¸€ -> ì˜ë¬¸)\n",
        "    rename_map = {\n",
        "        'êµ¬ë¶„': 'job_role', 'ê¸°ì—…ëª…': 'company',\n",
        "        'ë³µì§€ ë° ê¸‰ì—¬': 'salary', 'ì—…ë¬´ì™€ ì‚¶ì˜ ê· í˜•': 'wlb', 'ì‚¬ë‚´ë¬¸í™”': 'culture',\n",
        "        'ê²½ì˜ì§„': 'leadership', 'ìŠ¹ì§„ ê¸°íšŒ': 'promotion', 'ì¢…í•©í‰ì ': 'overall'\n",
        "    }\n",
        "    available_cols = set(df.columns)\n",
        "    valid_rename = {k:v for k,v in rename_map.items() if k in available_cols}\n",
        "    df = df.rename(columns=valid_rename)\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ ê²°í•© (ì¥ì  + ë‹¨ì  + ìš”ì•½ -> full_text)\n",
        "    df['full_text'] = (\n",
        "        df['ì¥ì '].fillna('').astype(str) + \" \" +\n",
        "        df['ë‹¨ì '].fillna('').astype(str) + \" \" +\n",
        "        df['ìš”ì•½'].fillna('').astype(str)\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# ========================================================================================\n",
        "# [Inference Class] ì¶”ì²œ ì‹œìŠ¤í…œ\n",
        "# ========================================================================================\n",
        "class AIRecommender:\n",
        "    def __init__(self, model_path, data_path):\n",
        "        # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print(f\"[Inference] ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}\")\n",
        "\n",
        "        # 2. í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
        "\n",
        "        # 3. ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ë³µì›\n",
        "        try:\n",
        "            # train ëª¨ë“ˆ ì˜ì¡´ì„± ì œê±° -> ë‚´ë¶€ í´ë˜ìŠ¤ ì‚¬ìš©\n",
        "            self.model = ReviewRatingRegressor(n_targets=6)\n",
        "\n",
        "            # [ìˆ˜ì •] ì½”ë© ê²½ë¡œ í˜¸í™˜ì„± ê°•í™”\n",
        "            if not os.path.exists(model_path):\n",
        "                 # ë§Œì•½ ì…ë ¥ëœ ê²½ë¡œì— ì—†ìœ¼ë©´ ì½”ë© ê¸°ë³¸ ê²½ë¡œ í™•ì¸\n",
        "                if os.path.exists('/content/review_rating_model.pt'):\n",
        "                    print(f\"âš ï¸ ì§€ì •ëœ ê²½ë¡œ({model_path})ì— íŒŒì¼ì´ ì—†ì–´ '/content/review_rating_model.pt'ë¥¼ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "                    model_path = '/content/review_rating_model.pt'\n",
        "\n",
        "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            print(f\"âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ê²½ë¡œ: {model_path})\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"âŒ ëª¨ë¸ íŒŒì¼({model_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\")\n",
        "\n",
        "        # 4. ì¶”ì²œ í›„ë³´êµ° ë°ì´í„° ì¤€ë¹„\n",
        "        self.data_path = data_path\n",
        "        self.df = self._load_and_preprocess_data()\n",
        "\n",
        "        # 5. ì „ì²´ ë°ì´í„° ì„ë² ë”© ìƒì„±\n",
        "        print(\"\\n[Inference] ì „ì²´ ê¸°ì—… ë°ì´í„°ì˜ ì„ë² ë”©(Vector)ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
        "        self.company_embeddings = self._get_embeddings(self.df['full_text'].tolist())\n",
        "        print(f\" -> ì„ë² ë”© ìƒì„± ì™„ë£Œ. (Shape: {self.company_embeddings.shape})\")\n",
        "\n",
        "    def _load_and_preprocess_data(self):\n",
        "        # 1. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° ê²½ë¡œ ë³´ì •\n",
        "        if not os.path.exists(self.data_path):\n",
        "            # ì½”ë© í™˜ê²½ ì˜ˆì™¸ ì²˜ë¦¬: ì—‘ì…€ íŒŒì¼ ìš°ì„  íƒìƒ‰\n",
        "            if os.path.exists('/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx'):\n",
        "                 self.data_path = '/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx'\n",
        "            # CSV íŒŒì¼ (ë³€í™˜ëœ ê²ƒ) ì°¨ì„  íƒìƒ‰\n",
        "            elif os.path.exists('/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx - Sheet1.csv'):\n",
        "                 self.data_path = '/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx - Sheet1.csv'\n",
        "            else:\n",
        "                raise FileNotFoundError(f\"ë°ì´í„° íŒŒì¼({self.data_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        print(f\"[Inference] ë°ì´í„° ë¡œë“œ ì¤‘... ({self.data_path})\")\n",
        "\n",
        "        # 2. í™•ì¥ìì— ë”°ë¥¸ ë¡œë“œ (Excel vs CSV)\n",
        "        if self.data_path.endswith('.xlsx') or self.data_path.endswith('.xls'):\n",
        "            try:\n",
        "                df = pd.read_excel(self.data_path)\n",
        "            except Exception as e:\n",
        "                raise ValueError(f\"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (openpyxl ì„¤ì¹˜ í™•ì¸ í•„ìš”): {e}\")\n",
        "        else:\n",
        "            # CSVë¡œ ì‹œë„í•˜ë˜ ì‹¤íŒ¨í•˜ë©´ Excelë¡œ ì¬ì‹œë„ (í™•ì¥ìê°€ ì˜ëª»ëœ ê²½ìš° ëŒ€ë¹„)\n",
        "            try:\n",
        "                df = pd.read_csv(self.data_path)\n",
        "            except:\n",
        "                try:\n",
        "                    df = pd.read_excel(self.data_path)\n",
        "                except Exception as e:\n",
        "                    raise ValueError(f\"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "        # ë‚´ë¶€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš©\n",
        "        df = local_preprocess_dataframe(df)\n",
        "        return df\n",
        "\n",
        "    def _get_embeddings(self, text_list):\n",
        "        embeddings = []\n",
        "        batch_size = 32\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(text_list), batch_size):\n",
        "                batch_texts = text_list[i:i+batch_size]\n",
        "\n",
        "                encoded = self.tokenizer.batch_encode_plus(\n",
        "                    batch_texts,\n",
        "                    max_length=128,\n",
        "                    padding='max_length',\n",
        "                    truncation=True,\n",
        "                    return_tensors='pt'\n",
        "                )\n",
        "\n",
        "                input_ids = encoded['input_ids'].to(self.device)\n",
        "                mask = encoded['attention_mask'].to(self.device)\n",
        "\n",
        "                # ëª¨ë¸ í†µê³¼ -> ì„ë² ë”© ì¶”ì¶œ\n",
        "                _, pooler_output = self.model(input_ids, mask)\n",
        "                embeddings.append(pooler_output.cpu().numpy())\n",
        "\n",
        "        return np.vstack(embeddings)\n",
        "\n",
        "    def recommend(self, user_query, top_k=3):\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        print(f\"ğŸ” ì‚¬ìš©ì ì…ë ¥: '{user_query}'\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        query_vec = self._get_embeddings([user_query])\n",
        "        sim_scores = cosine_similarity(query_vec, self.company_embeddings).flatten()\n",
        "        top_indices = sim_scores.argsort()[-top_k:][::-1]\n",
        "\n",
        "        print(f\"ğŸ¤– AI ì¶”ì²œ ê²°ê³¼ (Top {top_k}):\")\n",
        "\n",
        "        rank = 1\n",
        "        for idx in top_indices:\n",
        "            row = self.df.iloc[idx]\n",
        "            sim = sim_scores[idx]\n",
        "\n",
        "            c_name = row.get('company', 'Unknown')\n",
        "            role = row.get('job_role', 'Unknown')\n",
        "            rating = row.get('overall', 0.0)\n",
        "            summary = str(row.get('ìš”ì•½', ''))[:50] + \"...\"\n",
        "\n",
        "            print(f\"\\n[{rank}ìœ„] {c_name} ({role})\")\n",
        "            print(f\"   â€¢ ì í•©ë„(ìœ ì‚¬ë„): {sim:.4f}\")\n",
        "            print(f\"   â€¢ ì‹¤ì œ ì¢…í•©í‰ì : {rating}ì \")\n",
        "            print(f\"   â€¢ ë¦¬ë·° ìš”ì•½: {summary}\")\n",
        "            rank += 1\n",
        "\n",
        "    def predict_score(self, text):\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            text, max_length=128, padding='max_length', truncation=True, return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoded['input_ids'].to(self.device)\n",
        "        mask = encoded['attention_mask'].to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            scores, _ = self.model(input_ids, mask)\n",
        "            scores = scores.cpu().numpy()[0]\n",
        "\n",
        "        print(f\"\\nğŸ“Š '{text[:20]}...'ì— ëŒ€í•œ AI í‰ì  ì˜ˆì¸¡:\")\n",
        "        labels = ['ë³µì§€/ê¸‰ì—¬', 'ì›Œë¼ë°¸', 'ë¬¸í™”', 'ê²½ì˜ì§„', 'ìŠ¹ì§„', 'ì¢…í•©']\n",
        "        for label, score in zip(labels, scores):\n",
        "            print(f\"   - {label}: {score:.2f}ì \")\n",
        "\n",
        "# ========================================================================================\n",
        "# [Main Execution] ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ\n",
        "# ========================================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # ë°ì´í„° ê²½ë¡œ: ì½”ë©ì— ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼ ìš°ì„  (/content/...)\n",
        "    target_data_path = '/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx'\n",
        "\n",
        "    # ëª¨ë¸ ê²½ë¡œ: ì½”ë©ì— ìƒì„±ëœ .pt íŒŒì¼ ê²½ë¡œ\n",
        "    target_model_path = '/content/review_rating_model.pt'\n",
        "\n",
        "    if not os.path.exists(target_data_path) and not os.path.exists('/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx - Sheet1.csv'):\n",
        "         print(f\"âš ï¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{target_data_path}' ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    try:\n",
        "        rec_system = AIRecommender(\n",
        "            model_path=target_model_path,\n",
        "            data_path=target_data_path\n",
        "        )\n",
        "\n",
        "        # --- ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ---\n",
        "        print(\"\\nğŸ‘‡ [í…ŒìŠ¤íŠ¸ 1] ì›Œë¼ë°¸ ì¤‘ì‹œí˜•\")\n",
        "        rec_system.recommend(\"ì—°ë´‰ì€ ì ì–´ë„ ë˜ë‹ˆê¹Œ ì•¼ê·¼ ì—†ê³  ìˆ˜í‰ì ì¸ ê³³\", top_k=3)\n",
        "\n",
        "        print(\"\\nğŸ‘‡ [í…ŒìŠ¤íŠ¸ 2] ì„±ì¥/ë³´ìƒ ì¤‘ì‹œí˜•\")\n",
        "        rec_system.recommend(\"ì¼ì´ í˜ë“¤ì–´ë„ ë°°ìš¸ê²Œ ë§ê³  ì„±ê³¼ê¸‰ í™•ì‹¤í•œ ê³³\", top_k=3)\n",
        "\n",
        "        # print(\"\\nğŸ‘‡ [í…ŒìŠ¤íŠ¸ 3] ì ìˆ˜ ì˜ˆì¸¡\")\n",
        "        # rec_system.predict_score(\"ì•¼ê·¼ì´ ë§¤ì¼ ìˆê³  ì£¼ë§ ì¶œê·¼ë„ ê°•ìš”í•©ë‹ˆë‹¤. ì—°ë´‰ì€ ìµœì €ì„ê¸ˆ ìˆ˜ì¤€.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        print(\"1. í•™ìŠµ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ëª¨ë¸(pt íŒŒì¼)ì„ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "        print(\"2. ì—‘ì…€ ë°ì´í„° íŒŒì¼(.xlsx)ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
      ]
    }
  ]
}