ë‹¤ìŒ ì½”ë“œë¥¼ êµ¬ê¸€ ì½”ë© í™˜ê²½ì—ì„œ ì‹¤í–‰ì‹œí‚¤ëŠ” ìƒíƒœì—ì„œ ë§í¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# @title ğŸš€ ê¸°ì—… ì¶”ì²œ AI ì‹œìŠ¤í…œ ë°ëª¨ ì‹¤í–‰í•˜ê¸°
# ë¨¼ì € ì´ ì…€ì„ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  ì•±ì„ ì‹œì‘í•˜ì„¸ìš”.

# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
import sys
import subprocess
import os

def install_packages():
    print("â³ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜ ì¤‘ì…ë‹ˆë‹¤...")
    packages = ["gradio", "transformers", "torch", "pandas", "numpy", "scikit-learn", "openpyxl"]
    for package in packages:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
    print("âœ… ì„¤ì¹˜ ì™„ë£Œ!")

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ í•„ìš”í•œ ê²½ìš° ì„¤ì¹˜
try:
    import gradio as gr
    from transformers import AutoTokenizer
    from sklearn.metrics.pairwise import cosine_similarity
except ImportError:
    install_packages()

# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ì„¤ì¹˜ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ í•­ìƒ ì‹¤í–‰)
import gradio as gr
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoTokenizer, AutoModel

# ========================================================================================
# [Model Architecture] ëª¨ë¸ í´ë˜ìŠ¤ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼ ìœ ì§€)
# ========================================================================================
class ReviewRatingRegressor(nn.Module):
    def __init__(self, n_targets=6):
        super(ReviewRatingRegressor, self).__init__()
        self.bert = AutoModel.from_pretrained('klue/bert-base')
        self.drop = nn.Dropout(p=0.3)
        self.out = nn.Linear(self.bert.config.hidden_size, n_targets)

    def forward(self, input_ids, attention_mask):
        _, pooler_output = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            return_dict=False
        )
        output = self.drop(pooler_output)
        return self.out(output), pooler_output

# ========================================================================================
# [Preprocessing] ì „ì²˜ë¦¬ í•¨ìˆ˜
# ========================================================================================
def local_preprocess_dataframe(df):
    df.columns = [str(col).strip() for col in df.columns]
    rename_map = {
        'êµ¬ë¶„': 'job_role', 'ê¸°ì—…ëª…': 'company',
        'ë³µì§€ ë° ê¸‰ì—¬': 'salary', 'ì—…ë¬´ì™€ ì‚¶ì˜ ê· í˜•': 'wlb', 'ì‚¬ë‚´ë¬¸í™”': 'culture',
        'ê²½ì˜ì§„': 'leadership', 'ìŠ¹ì§„ ê¸°íšŒ': 'promotion', 'ì¢…í•©í‰ì ': 'overall'
    }
    available_cols = set(df.columns)
    valid_rename = {k:v for k,v in rename_map.items() if k in available_cols}
    df = df.rename(columns=valid_rename)

    # í…ìŠ¤íŠ¸ ê²°í•©
    df['full_text'] = (
        df['ì¥ì '].fillna('').astype(str) + " " +
        df['ë‹¨ì '].fillna('').astype(str) + " " +
        df['ìš”ì•½'].fillna('').astype(str)
    )
    return df

# ========================================================================================
# [Inference Class] ì¶”ì²œ ì‹œìŠ¤í…œ ë¡œì§ (Gradioìš© ìˆ˜ì • í¬í•¨)
# ========================================================================================
class AIRecommender:
    def __init__(self, model_path, data_path):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"[System] ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")

        self.tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = ReviewRatingRegressor(n_targets=6)
        if not os.path.exists(model_path):
             raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼({model_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
        
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.to(self.device)
        self.model.eval()

        # ë°ì´í„° ë¡œë“œ
        self.data_path = data_path
        self.df = self._load_and_preprocess_data()
        
        # ì„ë² ë”© ìƒì„± (ìºì‹±)
        print("[System] ë°ì´í„° ì„ë² ë”© ìƒì„± ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
        self.company_embeddings = self._get_embeddings(self.df['full_text'].tolist())
        print("[System] ì¤€ë¹„ ì™„ë£Œ!")

    def _load_and_preprocess_data(self):
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"âŒ ë°ì´í„° íŒŒì¼({self.data_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        try:
            if self.data_path.endswith('.csv'):
                df = pd.read_csv(self.data_path)
            else:
                df = pd.read_excel(self.data_path)
        except Exception as e:
            # CSV/Excel í˜¸í™˜ì„± ì¬ì‹œë„
            try:
                df = pd.read_csv(self.data_path)
            except:
                df = pd.read_excel(self.data_path)
        
        return local_preprocess_dataframe(df)

    def _get_embeddings(self, text_list):
        embeddings = []
        batch_size = 16 # ì½”ë© ë©”ëª¨ë¦¬ ê³ ë ¤í•˜ì—¬ ì¡°ì ˆ
        
        with torch.no_grad():
            for i in range(0, len(text_list), batch_size):
                batch_texts = text_list[i:i+batch_size]
                encoded = self.tokenizer.batch_encode_plus(
                    batch_texts, max_length=128, padding='max_length', truncation=True, return_tensors='pt'
                )
                input_ids = encoded['input_ids'].to(self.device)
                mask = encoded['attention_mask'].to(self.device)
                _, pooler_output = self.model(input_ids, mask)
                embeddings.append(pooler_output.cpu().numpy())
        return np.vstack(embeddings)

    # Gradioìš© ì¶”ì²œ í•¨ìˆ˜: DataFrame ë°˜í™˜
    def recommend_for_ui(self, user_query, top_k=5):
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_vec = self._get_embeddings([user_query])
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        sim_scores = cosine_similarity(query_vec, self.company_embeddings).flatten()
        
        # ìƒìœ„ Kê°œ ì¶”ì¶œ
        top_indices = sim_scores.argsort()[-top_k:][::-1]

        results = []
        for idx in top_indices:
            row = self.df.iloc[idx]
            results.append({
                "ìˆœìœ„": len(results) + 1,
                "ê¸°ì—…ëª…": row.get('company', 'Unknown'),
                "ì§ë¬´": row.get('job_role', '-'),
                "AI ì í•©ë„": f"{sim_scores[idx]:.4f}",
                "ì‹¤ì œ í‰ì ": row.get('overall', 0.0),
                "ë¦¬ë·° ìš”ì•½": str(row.get('ìš”ì•½', ''))[:100] + "..."
            })
        return pd.DataFrame(results)

    # Gradioìš© ì˜ˆì¸¡ í•¨ìˆ˜: Dictionary ë°˜í™˜
    def analyze_review(self, text):
        encoded = self.tokenizer.encode_plus(
            text, max_length=128, padding='max_length', truncation=True, return_tensors='pt'
        )
        input_ids = encoded['input_ids'].to(self.device)
        mask = encoded['attention_mask'].to(self.device)

        with torch.no_grad():
            scores, _ = self.model(input_ids, mask)
            scores = scores.cpu().numpy()[0]
        
        labels = ['ë³µì§€/ê¸‰ì—¬', 'ì›Œë¼ë°¸', 'ì‚¬ë‚´ë¬¸í™”', 'ê²½ì˜ì§„', 'ìŠ¹ì§„ê¸°íšŒ', 'ì¢…í•©í‰ì ']
        # 5ì  ë§Œì  í´ë¦¬í•‘
        scores = np.clip(scores, 0, 5)
        return {label: float(score) for label, score in zip(labels, scores)}

# ========================================================================================
# [Gradio UI] ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
# ========================================================================================

# ì „ì—­ ë³€ìˆ˜ ì„¤ì • (ì‹œìŠ¤í…œ ë¡œë”© ìƒíƒœ ê´€ë¦¬)
recommender_system = None

def load_system():
    global recommender_system
    # ì½”ë© ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    model_path = '/content/review_rating_model.pt'
    data_path = '/content/í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx'
    
    # íŒŒì¼ í™•ì¸
    if not os.path.exists(model_path) or not os.path.exists(data_path):
        return "âš ï¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¢Œì¸¡ íŒŒì¼ ë©”ë‰´ì— 'review_rating_model.pt'ì™€ 'í†µí•©_ë¦¬ë·°_ê¸°ì—…ì¤‘ë³µì œê±°.xlsx'ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    try:
        if recommender_system is None:
            recommender_system = AIRecommender(model_path, data_path)
        return "âœ… ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ! ì´ì œ ì¶”ì²œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def get_recommendation(query):
    if recommender_system is None:
        return pd.DataFrame({"ì˜¤ë¥˜": ["ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒë‹¨ì˜ 'ì‹œìŠ¤í…œ ì‹œì‘í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."]})
    return recommender_system.recommend_for_ui(query, top_k=5)

def get_analysis(review_text):
    if recommender_system is None:
        return {"ì˜¤ë¥˜": 0}
    return recommender_system.analyze_review(review_text)

# í…Œë§ˆ ë° UI ìŠ¤íƒ€ì¼ ì„¤ì •
theme = gr.themes.Soft(
    primary_hue="indigo",
    secondary_hue="blue",
).set(
    button_primary_background_fill="*primary_500",
    button_primary_background_fill_hover="*primary_600",
)

with gr.Blocks(theme=theme, title="AI ê¸°ì—… ì¶”ì²œ ì„œë¹„ìŠ¤") as demo:
    gr.Markdown(
        """
        # ğŸ¢ AI Enterprise Recommender
        **AIê°€ ë‹¹ì‹ ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ì—¬ ë”± ë§ëŠ” ê¸°ì—…ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.**
        *(BERT ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìš©)*
        """
    )
    
    with gr.Row():
        load_btn = gr.Button("ğŸ”„ ì‹œìŠ¤í…œ ì‹œì‘í•˜ê¸° (íŒŒì¼ ì—…ë¡œë“œ í›„ í´ë¦­)", variant="secondary")
        system_status = gr.Textbox(label="ì‹œìŠ¤í…œ ìƒíƒœ", value="ëŒ€ê¸° ì¤‘...", interactive=False)
    
    load_btn.click(load_system, inputs=None, outputs=system_status)

    with gr.Tabs():
        # [Tab 1] ê¸°ì—… ì¶”ì²œ
        with gr.TabItem("ğŸ” ê¸°ì—… ì¶”ì²œ ë°›ê¸°"):
            gr.Markdown("ì›í•˜ëŠ” íšŒì‚¬ì˜ ë¶„ìœ„ê¸°, ì¡°ê±´ ë“±ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”.")
            with gr.Row():
                with gr.Column(scale=4):
                    query_input = gr.Textbox(
                        placeholder="ì˜ˆ: ì—°ë´‰ì€ ì ì–´ë„ ë˜ë‹ˆ ì›Œë¼ë°¸ì´ í™•ì‹¤í•˜ê³  ìˆ˜í‰ì ì¸ ë¬¸í™”ê°€ ìˆëŠ” ê³³",
                        label="ë‚˜ì˜ ì„ í˜¸ ì¡°ê±´",
                        lines=2
                    )
                with gr.Column(scale=1):
                    rec_btn = gr.Button("ì¶”ì²œ ê²€ìƒ‰", variant="primary", size="lg")
            
            rec_output = gr.Dataframe(
                headers=["ìˆœìœ„", "ê¸°ì—…ëª…", "ì§ë¬´", "AI ì í•©ë„", "ì‹¤ì œ í‰ì ", "ë¦¬ë·° ìš”ì•½"],
                label="ì¶”ì²œ ê²°ê³¼",
                wrap=True
            )
            
            rec_btn.click(get_recommendation, inputs=query_input, outputs=rec_output)
            query_input.submit(get_recommendation, inputs=query_input, outputs=rec_output) # ì—”í„°í‚¤ ì§€ì›

        # [Tab 2] ë¦¬ë·° ë¶„ì„ (ë³´ë„ˆìŠ¤ ê¸°ëŠ¥)
        with gr.TabItem("ğŸ“Š ë¦¬ë·° ì ìˆ˜ ì˜ˆì¸¡"):
            gr.Markdown("ì‘ì„±í•œ ë¦¬ë·°ê°€ AIì—ê²Œ ëª‡ ì ìœ¼ë¡œ í‰ê°€ë°›ì„ì§€ ì˜ˆì¸¡í•´ ë´…ë‹ˆë‹¤.")
            review_input = gr.Textbox(
                placeholder="ì˜ˆ: ê²½ì˜ì§„ì´ ì†Œí†µì„ ì•ˆ í•˜ê³  ì•¼ê·¼ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.",
                label="ê¸°ì—… ë¦¬ë·° ì…ë ¥",
                lines=3
            )
            analyze_btn = gr.Button("ì ìˆ˜ ì˜ˆì¸¡", variant="primary")
            analysis_output = gr.Label(label="AI ì˜ˆì¸¡ ì ìˆ˜ (í•­ëª©ë³„)", num_top_classes=6)
            
            analyze_btn.click(get_analysis, inputs=review_input, outputs=analysis_output)

    gr.Markdown("--- \n *Powered by Google Colab & Gradio*")

# ì‹¤í–‰ (share=Trueë¡œ ì™¸ë¶€ ë§í¬ ìƒì„±)
if __name__ == "__main__":
    print("ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    demo.launch(share=True, debug=True)

ë‹¤ìŒê³¼ ê°™ì€ UIê°€ ê°„ë‹¨í•˜ê²Œ êµ¬í˜„ë©ë‹ˆë‹¤.


